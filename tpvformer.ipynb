{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0a2325-0ebf-4f02-ab9b-e9b9226e3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sray.utils.imgs_info import build_imgs_info, imgs_info_to_torch\n",
    "from sray.dataset.database import ScannetDatabase\n",
    "from sray.utils.imgs_info import build_imgs_info\n",
    "import numpy as np\n",
    "from mmengine.config import Config\n",
    "from mmseg.models import build_segmentor\n",
    "from sray.network.tpvformer10 import *\n",
    "# from sray.network.tpvformer10.tpv_head import TPVFormerHead,CustomPositionalEncoding\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9917fc-7813-4068-99cf-9f396ba97360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'scannet/scene0188_00/black_320'\n",
    "dataset = ScannetDatabase(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8f3eb5-39c4-4bea-b8f0-bb4880f94f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_info = build_imgs_info(dataset,[10,20,30,40,50,60,70,80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c147bb-0fc7-4c2a-9cb4-1d2d7c903aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imgs_mmseg',\n",
       " 'seg_logits',\n",
       " 'pred_sem_seg',\n",
       " 'mlvl_feats',\n",
       " 'imgs',\n",
       " 'poses',\n",
       " 'Ks',\n",
       " 'depth_range',\n",
       " 'masks',\n",
       " 'labels',\n",
       " 'depth']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ref_img_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed1faff-aea0-49fa-a229-4563c448e82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_img_info['poses'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7bf1ee-4864-41a8-af47-896fd700ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_img_metas(ref_img_info,img_H = 280,img_W = 320):\n",
    "\n",
    "    img_metas=[]\n",
    "    d = {\n",
    "        'img_shape' : [[img_H, img_W]],\n",
    "    }\n",
    "    img_metas = []\n",
    "    for pose,k in zip(ref_img_info['poses'],ref_img_info['Ks']):\n",
    "        lidar2cam_rt = np.eye(4)\n",
    "        lidar2cam_rt[:3, :4] = pose[:3,:4]\n",
    "        intrinsic = np.eye(4)\n",
    "        intrinsic[:k.shape[0], :k.shape[1]] = k\n",
    "        lidar2img = intrinsic  @ lidar2cam_rt\n",
    "        ret = d.copy()\n",
    "        ret['lidar2img'] = lidar2img\n",
    "        img_metas.append(ret)\n",
    "    return img_metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7088680-9e34-4261-994f-843e8307277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_metas = build_img_metas(ref_img_info)\n",
    "ref_img_info['img_metas']  =img_metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23aba63c-02bf-4c78-a561-9c7f3b2a7820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref_img_info['img_metas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ac0150-937a-4af9-a47f-d86d954256fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_info = imgs_info_to_torch(ref_img_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01e16ad-5d70-495d-bfaf-6f2a298bd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(model_config):\n",
    "    model = build_segmentor(model_config)\n",
    "    model.init_weights()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964facd3-150d-4617-9664-afba92f12d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('sray/network/tpvformer10/tpv_config.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d39c7ba-2e5f-41cc-b4ea-2f1289d89c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'TPVFormer',\n",
       " 'use_grid_mask': True,\n",
       " 'tpv_aggregator': {'type': 'TPVAggregator',\n",
       "  'tpv_h': 160,\n",
       "  'tpv_w': 160,\n",
       "  'tpv_z': 64,\n",
       "  'nbr_classes': 17,\n",
       "  'in_dims': 64,\n",
       "  'hidden_dims': 128,\n",
       "  'out_dims': 64,\n",
       "  'scale_h': 1,\n",
       "  'scale_w': 1,\n",
       "  'scale_z': 1},\n",
       " 'img_backbone': {'type': 'ResNet',\n",
       "  'depth': 18,\n",
       "  'num_stages': 4,\n",
       "  'out_indices': (1, 2, 3),\n",
       "  'frozen_stages': 1,\n",
       "  'norm_cfg': {'type': 'BN2d', 'requires_grad': False},\n",
       "  'norm_eval': True,\n",
       "  'style': 'caffe',\n",
       "  'dcn': None,\n",
       "  'stage_with_dcn': (False, False, True, True)},\n",
       " 'img_neck': {'type': 'FPN',\n",
       "  'in_channels': [128, 256, 512],\n",
       "  'out_channels': 64,\n",
       "  'start_level': 0,\n",
       "  'add_extra_convs': 'on_output',\n",
       "  'num_outs': 4,\n",
       "  'relu_before_extra_convs': True},\n",
       " 'tpv_head': {'type': 'TPVFormerHead',\n",
       "  'tpv_h': 160,\n",
       "  'tpv_w': 160,\n",
       "  'tpv_z': 64,\n",
       "  'pc_range': [-8, -8, -4.0, 8, 8, 4.0],\n",
       "  'num_feature_levels': 4,\n",
       "  'num_cams': 8,\n",
       "  'embed_dims': 64,\n",
       "  'encoder': {'type': 'TPVFormerEncoder',\n",
       "   'tpv_h': 160,\n",
       "   'tpv_w': 160,\n",
       "   'tpv_z': 64,\n",
       "   'num_layers': 5,\n",
       "   'pc_range': [-8, -8, -4.0, 8, 8, 4.0],\n",
       "   'num_points_in_pillar': [16, 32, 32],\n",
       "   'num_points_in_pillar_cross_view': [16, 16, 16],\n",
       "   'return_intermediate': False,\n",
       "   'transformerlayers': [{'type': 'TPVFormerLayer',\n",
       "     'attn_cfgs': [{'type': 'TPVCrossViewHybridAttention',\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64,\n",
       "       'num_anchors': 16,\n",
       "       'embed_dims': 64,\n",
       "       'num_heads': 4,\n",
       "       'num_points': 16,\n",
       "       'init_mode': 0},\n",
       "      {'type': 'TPVImageCrossAttention',\n",
       "       'pc_range': [-8, -8, -4.0, 8, 8, 4.0],\n",
       "       'num_cams': 8,\n",
       "       'deformable_attention': {'type': 'TPVMSDeformableAttention3D',\n",
       "        'embed_dims': 64,\n",
       "        'num_heads': 4,\n",
       "        'num_points': [16, 32, 32],\n",
       "        'num_z_anchors': [16, 32, 32],\n",
       "        'num_levels': 4,\n",
       "        'floor_sampling_offset': False,\n",
       "        'tpv_h': 160,\n",
       "        'tpv_w': 160,\n",
       "        'tpv_z': 64},\n",
       "       'embed_dims': 64,\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64}],\n",
       "     'feedforward_channels': 128,\n",
       "     'ffn_dropout': 0.1,\n",
       "     'operation_order': ('self_attn',\n",
       "      'norm',\n",
       "      'cross_attn',\n",
       "      'norm',\n",
       "      'ffn',\n",
       "      'norm')},\n",
       "    {'type': 'TPVFormerLayer',\n",
       "     'attn_cfgs': [{'type': 'TPVCrossViewHybridAttention',\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64,\n",
       "       'num_anchors': 16,\n",
       "       'embed_dims': 64,\n",
       "       'num_heads': 4,\n",
       "       'num_points': 16,\n",
       "       'init_mode': 0},\n",
       "      {'type': 'TPVImageCrossAttention',\n",
       "       'pc_range': [-8, -8, -4.0, 8, 8, 4.0],\n",
       "       'num_cams': 8,\n",
       "       'deformable_attention': {'type': 'TPVMSDeformableAttention3D',\n",
       "        'embed_dims': 64,\n",
       "        'num_heads': 4,\n",
       "        'num_points': [16, 32, 32],\n",
       "        'num_z_anchors': [16, 32, 32],\n",
       "        'num_levels': 4,\n",
       "        'floor_sampling_offset': False,\n",
       "        'tpv_h': 160,\n",
       "        'tpv_w': 160,\n",
       "        'tpv_z': 64},\n",
       "       'embed_dims': 64,\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64}],\n",
       "     'feedforward_channels': 128,\n",
       "     'ffn_dropout': 0.1,\n",
       "     'operation_order': ('self_attn',\n",
       "      'norm',\n",
       "      'cross_attn',\n",
       "      'norm',\n",
       "      'ffn',\n",
       "      'norm')},\n",
       "    {'type': 'TPVFormerLayer',\n",
       "     'attn_cfgs': [{'type': 'TPVCrossViewHybridAttention',\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64,\n",
       "       'num_anchors': 16,\n",
       "       'embed_dims': 64,\n",
       "       'num_heads': 4,\n",
       "       'num_points': 16,\n",
       "       'init_mode': 0},\n",
       "      {'type': 'TPVImageCrossAttention',\n",
       "       'pc_range': [-8, -8, -4.0, 8, 8, 4.0],\n",
       "       'num_cams': 8,\n",
       "       'deformable_attention': {'type': 'TPVMSDeformableAttention3D',\n",
       "        'embed_dims': 64,\n",
       "        'num_heads': 4,\n",
       "        'num_points': [16, 32, 32],\n",
       "        'num_z_anchors': [16, 32, 32],\n",
       "        'num_levels': 4,\n",
       "        'floor_sampling_offset': False,\n",
       "        'tpv_h': 160,\n",
       "        'tpv_w': 160,\n",
       "        'tpv_z': 64},\n",
       "       'embed_dims': 64,\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64}],\n",
       "     'feedforward_channels': 128,\n",
       "     'ffn_dropout': 0.1,\n",
       "     'operation_order': ('self_attn',\n",
       "      'norm',\n",
       "      'cross_attn',\n",
       "      'norm',\n",
       "      'ffn',\n",
       "      'norm')},\n",
       "    {'type': 'TPVFormerLayer',\n",
       "     'attn_cfgs': [{'type': 'TPVCrossViewHybridAttention',\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64,\n",
       "       'num_anchors': 16,\n",
       "       'embed_dims': 64,\n",
       "       'num_heads': 4,\n",
       "       'num_points': 16,\n",
       "       'init_mode': 0}],\n",
       "     'feedforward_channels': 128,\n",
       "     'ffn_dropout': 0.1,\n",
       "     'operation_order': ('self_attn', 'norm', 'ffn', 'norm')},\n",
       "    {'type': 'TPVFormerLayer',\n",
       "     'attn_cfgs': [{'type': 'TPVCrossViewHybridAttention',\n",
       "       'tpv_h': 160,\n",
       "       'tpv_w': 160,\n",
       "       'tpv_z': 64,\n",
       "       'num_anchors': 16,\n",
       "       'embed_dims': 64,\n",
       "       'num_heads': 4,\n",
       "       'num_points': 16,\n",
       "       'init_mode': 0}],\n",
       "     'feedforward_channels': 128,\n",
       "     'ffn_dropout': 0.1,\n",
       "     'operation_order': ('self_attn', 'norm', 'ffn', 'norm')}]},\n",
       "  'positional_encoding': {'type': 'CustomPositionalEncoding',\n",
       "   'num_feats': [24, 24, 16],\n",
       "   'h': 160,\n",
       "   'w': 160,\n",
       "   'z': 64}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ccdf2a-7f01-4d28-adb8-735a1dac6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengshun.wang/pjs/mmsegmentation/mmseg/models/builder.py:29: UserWarning: ``build_head`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_head`` would be deprecated soon, please use '\n",
      "/home/chengshun.wang/pjs/Semantic-Ray/sray/network/tpvformer10/modules/tpvformer_layer.py:69: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. \n",
      "  warnings.warn(\n",
      "/home/chengshun.wang/pjs/Semantic-Ray/sray/network/tpvformer10/modules/tpvformer_layer.py:69: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. \n",
      "  warnings.warn(\n",
      "/home/chengshun.wang/pjs/mmsegmentation/mmseg/models/builder.py:15: UserWarning: ``build_backbone`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_backbone`` would be deprecated soon, please use '\n",
      "/home/chengshun.wang/pjs/mmsegmentation/mmseg/models/builder.py:22: UserWarning: ``build_neck`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_neck`` would be deprecated soon, please use '\n",
      "2023-10-26 03:02:44,154 - mmcv - INFO - \n",
      "tpv_head.level_embeds - torch.Size([4, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,154 - mmcv - INFO - \n",
      "tpv_head.cams_embeds - torch.Size([8, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,155 - mmcv - INFO - \n",
      "tpv_head.positional_encoding.h_embed.weight - torch.Size([160, 24]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,155 - mmcv - INFO - \n",
      "tpv_head.positional_encoding.w_embed.weight - torch.Size([160, 24]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,156 - mmcv - INFO - \n",
      "tpv_head.positional_encoding.z_embed.weight - torch.Size([64, 16]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,156 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.output_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,157 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.output_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,157 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.output_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,157 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.output_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,158 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.output_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,158 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.output_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,159 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.sampling_offsets.0.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,159 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.sampling_offsets.0.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,159 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.sampling_offsets.1.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,160 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.sampling_offsets.1.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,160 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.sampling_offsets.2.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,161 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.sampling_offsets.2.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,161 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.attention_weights.0.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,161 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.attention_weights.0.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,162 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.attention_weights.1.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,162 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.attention_weights.1.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,162 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.attention_weights.2.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,163 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.attention_weights.2.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,163 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.value_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,164 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.value_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,164 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.value_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,164 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.value_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,165 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.value_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,165 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.0.value_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,165 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.0.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,166 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.0.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,166 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.1.weight - torch.Size([1024, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,167 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,167 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.2.weight - torch.Size([1024, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,167 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,168 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.attention_weights.0.weight - torch.Size([256, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,168 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.attention_weights.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,168 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.attention_weights.1.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,169 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.attention_weights.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,169 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.attention_weights.2.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,170 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.attention_weights.2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,170 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.value_proj.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,170 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.deformable_attention.value_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,171 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.output_proj.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,171 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.attentions.1.output_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,171 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([128, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,172 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,172 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([64, 128]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,173 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,173 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.norms.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,173 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.norms.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,174 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.norms.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,174 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.norms.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,174 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.norms.2.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,175 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.0.norms.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,175 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.output_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,176 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.output_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,176 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.output_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,176 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.output_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,177 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.output_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,177 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.output_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,177 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.sampling_offsets.0.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,178 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.sampling_offsets.0.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,178 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.sampling_offsets.1.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,178 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.sampling_offsets.1.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,179 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.sampling_offsets.2.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,179 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.sampling_offsets.2.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,180 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.attention_weights.0.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,180 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.attention_weights.0.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,180 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.attention_weights.1.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,181 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.attention_weights.1.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,181 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.attention_weights.2.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,181 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.attention_weights.2.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,182 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.value_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,182 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.value_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,183 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.value_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,183 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.value_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,183 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.value_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,184 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.0.value_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,184 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.0.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,184 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.0.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,185 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.1.weight - torch.Size([1024, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,185 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,185 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.2.weight - torch.Size([1024, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,186 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,186 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.attention_weights.0.weight - torch.Size([256, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,187 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.attention_weights.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,187 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.attention_weights.1.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,187 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.attention_weights.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,188 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.attention_weights.2.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,188 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.attention_weights.2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,188 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.value_proj.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,189 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.deformable_attention.value_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,189 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.output_proj.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,190 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.attentions.1.output_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,190 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([128, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,190 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,191 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([64, 128]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,191 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,191 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.norms.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,192 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.norms.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,192 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.norms.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,193 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.norms.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,193 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.norms.2.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,193 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.1.norms.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,194 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.output_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,194 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.output_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,195 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.output_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,195 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.output_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,195 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.output_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,196 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.output_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,196 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.sampling_offsets.0.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,196 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.sampling_offsets.0.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,197 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.sampling_offsets.1.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,197 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.sampling_offsets.1.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,197 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.sampling_offsets.2.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,198 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.sampling_offsets.2.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,198 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.attention_weights.0.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,199 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.attention_weights.0.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,199 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.attention_weights.1.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,199 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.attention_weights.1.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,200 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.attention_weights.2.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,200 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.attention_weights.2.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,200 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.value_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,201 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.value_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,201 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.value_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,202 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.value_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,202 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.value_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,202 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.0.value_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,203 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.0.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,203 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.0.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,203 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.1.weight - torch.Size([1024, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,204 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,204 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.2.weight - torch.Size([1024, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,205 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,205 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.attention_weights.0.weight - torch.Size([256, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,205 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.attention_weights.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,206 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.attention_weights.1.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,206 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.attention_weights.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,206 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.attention_weights.2.weight - torch.Size([512, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,207 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.attention_weights.2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,207 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.value_proj.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,208 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.deformable_attention.value_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,208 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.output_proj.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,208 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.attentions.1.output_proj.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,209 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([128, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,209 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,209 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([64, 128]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,210 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,210 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.norms.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,211 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.norms.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,211 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.norms.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,211 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.norms.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,212 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.norms.2.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,212 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.2.norms.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,212 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.output_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,213 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.output_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,213 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.output_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,213 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.output_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,214 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.output_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,214 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.output_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,215 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.sampling_offsets.0.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,215 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.sampling_offsets.0.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,215 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.sampling_offsets.1.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,216 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.sampling_offsets.1.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,216 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.sampling_offsets.2.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,216 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.sampling_offsets.2.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,217 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.attention_weights.0.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,217 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.attention_weights.0.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,218 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.attention_weights.1.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,218 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.attention_weights.1.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,218 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.attention_weights.2.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,219 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.attention_weights.2.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,219 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.value_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,219 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.value_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,220 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.value_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,220 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.value_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,221 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.value_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,221 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.attentions.0.value_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,221 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([128, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,222 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,222 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([64, 128]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,222 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,223 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.norms.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,223 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.norms.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,224 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.norms.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,224 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.3.norms.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,224 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.output_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,225 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.output_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,225 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.output_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,225 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.output_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,226 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.output_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,226 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.output_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,227 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.sampling_offsets.0.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,227 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.sampling_offsets.0.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,227 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.sampling_offsets.1.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,228 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.sampling_offsets.1.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,228 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.sampling_offsets.2.weight - torch.Size([384, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,228 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.sampling_offsets.2.bias - torch.Size([384]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,229 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.attention_weights.0.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,229 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.attention_weights.0.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,230 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.attention_weights.1.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,230 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.attention_weights.1.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,230 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.attention_weights.2.weight - torch.Size([204, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,231 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.attention_weights.2.bias - torch.Size([204]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,231 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.value_proj.0.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,231 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.value_proj.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,232 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.value_proj.1.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,232 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.value_proj.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,233 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.value_proj.2.weight - torch.Size([64, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,233 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.attentions.0.value_proj.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,233 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([128, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,234 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,234 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([64, 128]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,234 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,235 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.norms.0.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,235 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.norms.0.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,235 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.norms.1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,236 - mmcv - INFO - \n",
      "tpv_head.encoder.layers.4.norms.1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,236 - mmcv - INFO - \n",
      "tpv_head.tpv_embedding_hw.weight - torch.Size([25600, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,237 - mmcv - INFO - \n",
      "tpv_head.tpv_embedding_zh.weight - torch.Size([10240, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,237 - mmcv - INFO - \n",
      "tpv_head.tpv_embedding_wz.weight - torch.Size([10240, 64]): \n",
      "Initialized by user-defined `init_weights` in TPVFormerHead  \n",
      " \n",
      "2023-10-26 03:02:44,237 - mmcv - INFO - \n",
      "img_backbone.conv1.weight - torch.Size([64, 3, 7, 7]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,238 - mmcv - INFO - \n",
      "img_backbone.bn1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,238 - mmcv - INFO - \n",
      "img_backbone.bn1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,239 - mmcv - INFO - \n",
      "img_backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,239 - mmcv - INFO - \n",
      "img_backbone.layer1.0.bn1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,239 - mmcv - INFO - \n",
      "img_backbone.layer1.0.bn1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,240 - mmcv - INFO - \n",
      "img_backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,240 - mmcv - INFO - \n",
      "img_backbone.layer1.0.bn2.weight - torch.Size([64]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,241 - mmcv - INFO - \n",
      "img_backbone.layer1.0.bn2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,241 - mmcv - INFO - \n",
      "img_backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,241 - mmcv - INFO - \n",
      "img_backbone.layer1.1.bn1.weight - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,242 - mmcv - INFO - \n",
      "img_backbone.layer1.1.bn1.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,242 - mmcv - INFO - \n",
      "img_backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,243 - mmcv - INFO - \n",
      "img_backbone.layer1.1.bn2.weight - torch.Size([64]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,243 - mmcv - INFO - \n",
      "img_backbone.layer1.1.bn2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,243 - mmcv - INFO - \n",
      "img_backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,244 - mmcv - INFO - \n",
      "img_backbone.layer2.0.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,244 - mmcv - INFO - \n",
      "img_backbone.layer2.0.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,245 - mmcv - INFO - \n",
      "img_backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,245 - mmcv - INFO - \n",
      "img_backbone.layer2.0.bn2.weight - torch.Size([128]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,245 - mmcv - INFO - \n",
      "img_backbone.layer2.0.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,246 - mmcv - INFO - \n",
      "img_backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,246 - mmcv - INFO - \n",
      "img_backbone.layer2.0.downsample.1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,246 - mmcv - INFO - \n",
      "img_backbone.layer2.0.downsample.1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,247 - mmcv - INFO - \n",
      "img_backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,247 - mmcv - INFO - \n",
      "img_backbone.layer2.1.bn1.weight - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,248 - mmcv - INFO - \n",
      "img_backbone.layer2.1.bn1.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,248 - mmcv - INFO - \n",
      "img_backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,248 - mmcv - INFO - \n",
      "img_backbone.layer2.1.bn2.weight - torch.Size([128]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,249 - mmcv - INFO - \n",
      "img_backbone.layer2.1.bn2.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,249 - mmcv - INFO - \n",
      "img_backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,250 - mmcv - INFO - \n",
      "img_backbone.layer3.0.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,250 - mmcv - INFO - \n",
      "img_backbone.layer3.0.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,250 - mmcv - INFO - \n",
      "img_backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,251 - mmcv - INFO - \n",
      "img_backbone.layer3.0.bn2.weight - torch.Size([256]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,251 - mmcv - INFO - \n",
      "img_backbone.layer3.0.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,252 - mmcv - INFO - \n",
      "img_backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,252 - mmcv - INFO - \n",
      "img_backbone.layer3.0.downsample.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,252 - mmcv - INFO - \n",
      "img_backbone.layer3.0.downsample.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,253 - mmcv - INFO - \n",
      "img_backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,253 - mmcv - INFO - \n",
      "img_backbone.layer3.1.bn1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,253 - mmcv - INFO - \n",
      "img_backbone.layer3.1.bn1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,254 - mmcv - INFO - \n",
      "img_backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,254 - mmcv - INFO - \n",
      "img_backbone.layer3.1.bn2.weight - torch.Size([256]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,255 - mmcv - INFO - \n",
      "img_backbone.layer3.1.bn2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,255 - mmcv - INFO - \n",
      "img_backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,255 - mmcv - INFO - \n",
      "img_backbone.layer4.0.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,256 - mmcv - INFO - \n",
      "img_backbone.layer4.0.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,256 - mmcv - INFO - \n",
      "img_backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,257 - mmcv - INFO - \n",
      "img_backbone.layer4.0.bn2.weight - torch.Size([512]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,257 - mmcv - INFO - \n",
      "img_backbone.layer4.0.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,257 - mmcv - INFO - \n",
      "img_backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,258 - mmcv - INFO - \n",
      "img_backbone.layer4.0.downsample.1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,258 - mmcv - INFO - \n",
      "img_backbone.layer4.0.downsample.1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,259 - mmcv - INFO - \n",
      "img_backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,259 - mmcv - INFO - \n",
      "img_backbone.layer4.1.bn1.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,259 - mmcv - INFO - \n",
      "img_backbone.layer4.1.bn1.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,260 - mmcv - INFO - \n",
      "img_backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): \n",
      "KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,260 - mmcv - INFO - \n",
      "img_backbone.layer4.1.bn2.weight - torch.Size([512]): \n",
      "ConstantInit: val=0, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,261 - mmcv - INFO - \n",
      "img_backbone.layer4.1.bn2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,261 - mmcv - INFO - \n",
      "img_neck.lateral_convs.0.conv.weight - torch.Size([64, 128, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,261 - mmcv - INFO - \n",
      "img_neck.lateral_convs.0.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,262 - mmcv - INFO - \n",
      "img_neck.lateral_convs.1.conv.weight - torch.Size([64, 256, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,262 - mmcv - INFO - \n",
      "img_neck.lateral_convs.1.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,263 - mmcv - INFO - \n",
      "img_neck.lateral_convs.2.conv.weight - torch.Size([64, 512, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,263 - mmcv - INFO - \n",
      "img_neck.lateral_convs.2.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,263 - mmcv - INFO - \n",
      "img_neck.fpn_convs.0.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,264 - mmcv - INFO - \n",
      "img_neck.fpn_convs.0.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,264 - mmcv - INFO - \n",
      "img_neck.fpn_convs.1.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,265 - mmcv - INFO - \n",
      "img_neck.fpn_convs.1.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,265 - mmcv - INFO - \n",
      "img_neck.fpn_convs.2.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,265 - mmcv - INFO - \n",
      "img_neck.fpn_convs.2.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,266 - mmcv - INFO - \n",
      "img_neck.fpn_convs.3.conv.weight - torch.Size([64, 64, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2023-10-26 03:02:44,266 - mmcv - INFO - \n",
      "img_neck.fpn_convs.3.conv.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,266 - mmcv - INFO - \n",
      "tpv_aggregator.decoder.0.weight - torch.Size([128, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,267 - mmcv - INFO - \n",
      "tpv_aggregator.decoder.0.bias - torch.Size([128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,267 - mmcv - INFO - \n",
      "tpv_aggregator.decoder.2.weight - torch.Size([64, 128]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,268 - mmcv - INFO - \n",
      "tpv_aggregator.decoder.2.bias - torch.Size([64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,268 - mmcv - INFO - \n",
      "tpv_aggregator.classifier.weight - torch.Size([17, 64]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n",
      "2023-10-26 03:02:44,269 - mmcv - INFO - \n",
      "tpv_aggregator.classifier.bias - torch.Size([17]): \n",
      "The value is the same before and after calling `init_weights` of TPVFormer  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "my_model = model_builder(cfg.model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca005e61-2887-4589-af8c-0bba716af053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-8, -8, -4.0, 8, 8, 4.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.tpv_head.encoder.pc_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0867c9dc-6c98-4458-a9c1-5fc552b35b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpv_hw,tpv_zh,tpv_wz = my_model(img_metas=ref_img_info['img_metas'],img=ref_img_info['imgs'][None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a588b4-354c-4fe4-aebc-fe14f4cb2bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1519, -1.4062, -1.8597,  ..., -0.0708,  0.1429,  0.4717],\n",
       "          [-2.0356, -1.9693, -1.1195,  ...,  0.5641, -0.3887,  0.9794],\n",
       "          [-2.7295, -0.7180, -1.6982,  ..., -0.0984, -0.4568,  0.3929],\n",
       "          ...,\n",
       "          [ 0.7365,  0.1642,  0.7138,  ...,  0.2032,  2.1435,  1.3940],\n",
       "          [ 0.6291,  1.1392, -0.3433,  ..., -1.0481, -0.6113,  0.8371],\n",
       "          [-0.7565, -1.8308, -0.7792,  ..., -0.3452,  0.1050,  0.3485]],\n",
       "\n",
       "         [[ 1.5901,  1.1290,  1.0374,  ..., -0.5502, -0.9338, -1.0303],\n",
       "          [ 0.6859,  1.6061,  0.4410,  ...,  0.6342, -1.4760, -2.1971],\n",
       "          [ 0.5807,  1.3325,  1.1537,  ..., -0.7519, -2.4986, -2.1104],\n",
       "          ...,\n",
       "          [ 1.1667,  0.4242, -0.0357,  ..., -0.9584,  0.2288,  0.1296],\n",
       "          [ 0.3384, -0.1551,  0.3613,  ..., -0.6977,  0.1690, -0.9875],\n",
       "          [-0.4996, -0.2300, -0.1627,  ..., -1.0490, -0.3526, -0.6052]],\n",
       "\n",
       "         [[ 0.1712, -0.6607, -0.0332,  ..., -1.1934, -0.9618, -0.7588],\n",
       "          [-0.3532, -1.0614, -0.5673,  ..., -0.6842,  0.0460, -1.3084],\n",
       "          [-0.1274, -0.0372,  0.0112,  ..., -0.9629, -0.5721,  0.2220],\n",
       "          ...,\n",
       "          [ 1.5642,  1.2919,  0.9973,  ...,  0.3256,  0.3441,  0.3464],\n",
       "          [-0.3828,  0.6994,  0.7799,  ...,  1.2553,  0.7185, -0.5798],\n",
       "          [ 0.0988,  1.4546,  0.8991,  ...,  1.1084,  0.5801,  0.3303]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0253, -0.8290, -1.1818,  ..., -0.1572,  0.9645,  0.1601],\n",
       "          [-1.2622, -0.2387, -0.4588,  ...,  0.6668,  0.5463,  0.2520],\n",
       "          [-1.4193, -0.5144, -0.6647,  ...,  0.6648,  0.5928, -1.5310],\n",
       "          ...,\n",
       "          [ 0.9465,  0.5549,  0.3238,  ...,  0.1392,  0.1178,  0.0070],\n",
       "          [-0.4985,  0.5427, -0.0685,  ..., -0.1806,  0.0309, -0.1002],\n",
       "          [ 0.0409,  0.2663,  0.1207,  ..., -0.5765,  0.0293,  0.8149]],\n",
       "\n",
       "         [[-1.2166, -1.5952, -1.8734,  ..., -1.4880, -0.0197,  0.2138],\n",
       "          [-0.7565, -0.7409, -1.2252,  ..., -1.2200, -0.1428, -0.2595],\n",
       "          [-0.3640, -1.2781,  0.0378,  ..., -1.2961,  0.1121, -1.5135],\n",
       "          ...,\n",
       "          [ 0.0154, -0.2416, -0.3420,  ...,  0.2184, -0.4845, -0.2182],\n",
       "          [-0.6814, -0.2424, -1.2374,  ..., -0.9172, -0.3142, -0.5596],\n",
       "          [ 0.0974, -0.0388,  0.6933,  ..., -0.8809, -0.6804, -0.5026]],\n",
       "\n",
       "         [[ 0.4631, -0.0560, -0.1197,  ...,  0.1779,  1.1412,  1.4277],\n",
       "          [-0.1838,  0.0214, -0.6144,  ...,  0.1466,  0.0463,  0.6245],\n",
       "          [-0.6590,  0.2576,  0.1404,  ...,  0.3641,  0.3638,  0.2832],\n",
       "          ...,\n",
       "          [ 1.0553, -0.2166, -0.4395,  ...,  0.5855, -0.4796, -0.4662],\n",
       "          [-0.2079,  0.1016, -1.4789,  ...,  0.4362,  1.0088,  0.9389],\n",
       "          [-0.1191,  0.6080, -0.0218,  ..., -0.8302, -0.9908, -0.7207]]]],\n",
       "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 160\n",
    "w = 160\n",
    "z = 64\n",
    "tpv_hw.permute(0,2,1).reshape((1,-1,h,w))\n",
    "tpv_zh.permute(0,2,1).reshape((1,-1,z,h))\n",
    "tpv_wz.permute(0,2,1).reshape((1,-1,w,z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5ad83-414b-4330-9619-c518967eaea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = torch.tensor([[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d0534-c527-4dda-9c18-675ccdaa6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord[...,[0,1]],coord[...,[1,2]],coord[...,[2,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8acfe528-b9e7-4a61-a075-e58bc328842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(t, num_encodings=10):\n",
    "    \"\"\"\n",
    "    Encodes time t with a positional encoding.\n",
    "\n",
    "    :param t: Time tensor (shape: [batch_size, 1])\n",
    "    :param num_encodings: The number of positional encodings to generate\n",
    "    :return: Positionally encoded time (shape: [batch_size, num_encodings])\n",
    "    \"\"\"\n",
    "    # Generate a range of frequencies\n",
    "    frequencies = 2.0 ** torch.linspace(0.0, num_encodings - 1, num_encodings).unsqueeze(0)\n",
    "    # frequencies = frequencies.to(t.device)\n",
    "    # frequencies = frequencies.unsqueeze(0)\n",
    "    # assert False, f\"frequencies.shape {frequencies.shape} t.shape {t.shape}\"\n",
    "    # Encode t with these frequencies\n",
    "    pre_fix = t.shape[:-1]\n",
    "    dim  = t.shape[-1]\n",
    "    frequencies = frequencies.expand(np.prod(pre_fix)*dim,num_encodings)\n",
    "    t = t.reshape((-1,1)).expand(np.prod(pre_fix)*dim,num_encodings)\n",
    "    # encoded_t = t * frequencies\n",
    "    try:\n",
    "        encoded_t = t * frequencies.to(t.device)\n",
    "    except:\n",
    "        assert False, f\"t.shape: {t.shape}, frequencies.shape: {frequencies.shape}\"\n",
    "    # encoded_t = t * frequencies.to(t.device)\n",
    "    encoded_t = encoded_t.reshape(list(pre_fix)+[-1])\n",
    "\n",
    "    # Apply sin and cos to generate positional encodings\n",
    "    encoded_t = torch.cat([encoded_t.sin(), encoded_t.cos()], dim=-1)\n",
    "\n",
    "    return encoded_t.reshape(list(pre_fix)+[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc50fde8-2490-4ba3-89e7-bf7b187f955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding(torch.rand((1,3)),10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb175c44-b052-43b7-b681-496fd24df30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca9272-006c-48d3-9df3-0327f98c4eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344c170-059f-41f9-b1c2-90e50d6e37f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e3765-7c96-4c36-a4e9-fcb04650feb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cbf3c-405e-4221-8c5f-434b493a9a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50f77e-b7f6-4a2a-9c76-c4a759053da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fc859-0cf9-4ef8-a626-dd7f542eb186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
