{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "226b3779-1dc7-465b-8454-995db53eaf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import abc\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from natsort import natsorted\n",
    "\n",
    "from sray.utils.base_utils import downsample_gaussian_blur, pose_inverse\n",
    "from sray.dataset.semantic_utils import PointSegClassMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6295cc-85b4-4694-b518-70d1d465227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 1296, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = imread('/home/chengshun.wang/pjs/Semantic-Ray/data/scannet/scene0000_00/color/0.jpg')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9283fcef-cc4a-4aaf-a104-711b19556942",
   "metadata": {},
   "outputs": [],
   "source": [
    "scannet_train_scans_320 = np.loadtxt('configs/scannetv2_train_split.txt',dtype=str).tolist()\n",
    "scannet_val_scans_320 = np.loadtxt('configs/scannetv2_val_split.txt',dtype=str).tolist()\n",
    "scannet_test_scans_320 = np.loadtxt('configs/scannetv2_test_split.txt',dtype=str).tolist()\n",
    "scannet_train_scans_320 = [i.split('/')[1] for i in scannet_train_scans_320]\n",
    "scannet_test_scans_320 = [i.split('/')[1] for i in scannet_test_scans_320]\n",
    "scannet_val_scans_320 = [i.split('/')[1] for i in scannet_val_scans_320]\n",
    "split2file_list={\n",
    "    'train':scannet_train_scans_320,\n",
    "    'test':scannet_test_scans_320,\n",
    "    'val':scannet_val_scans_320,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "50d22131-9da5-4603-ac8b-341f5a6558f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 320\n",
    "root_dir = '/mnt/data/chengshun.wang/scannet_2d'\n",
    "data_dir = 'data/scannet/'\n",
    "ratio = image_size / 1296\n",
    "h, w = int(ratio*972), int(image_size)\n",
    "h, w = 240, int(image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d7ef48-b785-4f66-863a-7d5e73208485",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file = 'data/scannet/scannetv2-labels.combined.tsv'\n",
    "mapping_file = pd.read_csv(mapping_file, sep='\\t', header=0)\n",
    "scan_ids = mapping_file['id'].values\n",
    "nyu40_ids = mapping_file['nyu40id'].values\n",
    "scan2nyu = np.zeros(max(scan_ids) + 1, dtype=np.int32)\n",
    "for i in range(len(scan_ids)):\n",
    "    scan2nyu[scan_ids[i]] = nyu40_ids[i]\n",
    "scan2nyu = scan2nyu\n",
    "label_mapping = PointSegClassMapping(\n",
    "    valid_cat_ids=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
    "                   11, 12, 14, 16, 24, 28, 33, 34, 36, 39],\n",
    "    max_cat_id=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fd7b5e82-2a92-4436-836e-d9dffb206277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    img = imread(path)\n",
    "    if w != 1296:\n",
    "        img = cv2.resize(downsample_gaussian_blur(\n",
    "            img, ratio), (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa8b06e5-8849-4ca4-aa08-6bd53e22eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d',exist_ok=True)\n",
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d/img_dir/train',exist_ok=True)\n",
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d/img_dir/val',exist_ok=True)\n",
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d/img_dir/test',exist_ok=True)\n",
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d/ann_dir/train',exist_ok=True)\n",
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d/ann_dir/val',exist_ok=True)\n",
    "os.makedirs('/mnt/data/chengshun.wang/scannet_2d/ann_dir/test',exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0c59f45b-a361-4bc5-a8be-72cf702ef782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_by_id(scene_id,split):\n",
    "    \n",
    "    rgb_paths = sorted([x for x in glob.glob(os.path.join(\n",
    "                data_dir,scene_id, \"color\", \"*\")) if (x.endswith(\".jpg\") or x.endswith(\".png\"))])\n",
    "    ano_paths = sorted([x for x in glob.glob(os.path.join(\n",
    "                data_dir,scene_id, \"label-filt\", \"*\")) if (x.endswith(\".jpg\") or x.endswith(\".png\"))])\n",
    "    assert len(rgb_paths) == len(ano_paths)\n",
    "    for ind,rgb_path in enumerate(rgb_paths):\n",
    "        img = get_image(rgb_path)\n",
    "        \n",
    "        label = Image.open(ano_paths[ind])\n",
    "        label = np.asarray(label, dtype=np.int32)\n",
    "        label = np.ascontiguousarray(label)\n",
    "        label = cv2.resize(label, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "        label = label.astype(np.int32)\n",
    "        label = scan2nyu[label]\n",
    "        label = label_mapping(label)\n",
    "        basename = str(scene_id) +'_'+ os.path.basename(ano_paths[ind]).split('.')[0]\n",
    "        # print(basename)\n",
    "        Image.fromarray(label.astype('uint8'), mode='L').save(os.path.join(root_dir,'ann_dir',split,basename+'.png'))\n",
    "        rgb_file_name = str(scene_id) +'_'+ os.path.basename(rgb_path)\n",
    "        Image.fromarray(img.astype('uint8')).save(os.path.join(root_dir,'img_dir',split,rgb_file_name))\n",
    "        \n",
    "        # load_ = np.asarray(Image.open(os.path.join(root_dir,'ann_dir',split,basename+'.png')), dtype=np.int32)\n",
    "        # assert (load_==label).all()\n",
    "        rgb_file_name = str(scene_id) +'_'+ os.path.basename(rgb_path)\n",
    "        # shutil.copy(rgb_path,os.path.join(root_dir,'img_dir',split,rgb_file_name))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d68e274b-f7ff-43d7-b906-9d6c85796265",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset_by_id('scene0160_00','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "95e7d8c7-7c7c-44ea-9b45-77a4446834cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693c39e-60df-4c3c-929b-081aef80ceed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e02627f-99b5-48c4-aa02-3ea2ed2e1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('scene0000_00', 'train'), ('scene0002_00', 'train'), ('scene0003_00', 'train'), ('scene0004_00', 'train'), ('scene0005_00', 'train'), ('scene0006_00', 'train'), ('scene0007_00', 'train'), ('scene0008_00', 'train'), ('scene0009_00', 'train'), ('scene0010_00', 'train'), ('scene0011_00', 'train'), ('scene0012_00', 'train'), ('scene0013_00', 'train'), ('scene0014_00', 'train'), ('scene0015_00', 'train'), ('scene0016_00', 'train'), ('scene0017_00', 'train'), ('scene0018_00', 'train'), ('scene0019_00', 'train'), ('scene0020_00', 'train'), ('scene0021_00', 'train'), ('scene0022_00', 'train'), ('scene0023_00', 'train'), ('scene0024_00', 'train'), ('scene0025_00', 'train'), ('scene0026_00', 'train'), ('scene0027_00', 'train'), ('scene0028_00', 'train'), ('scene0029_00', 'train'), ('scene0030_00', 'train'), ('scene0031_00', 'train'), ('scene0032_00', 'train'), ('scene0033_00', 'train'), ('scene0034_00', 'train'), ('scene0035_00', 'train'), ('scene0036_00', 'train'), ('scene0037_00', 'train'), ('scene0038_00', 'train'), ('scene0039_00', 'train'), ('scene0040_00', 'train'), ('scene0041_00', 'train'), ('scene0042_00', 'train'), ('scene0043_00', 'train'), ('scene0044_00', 'train'), ('scene0045_00', 'train'), ('scene0046_00', 'train'), ('scene0047_00', 'train'), ('scene0048_00', 'train'), ('scene0049_00', 'train'), ('scene0050_00', 'train'), ('scene0051_00', 'train'), ('scene0052_00', 'train'), ('scene0053_00', 'train'), ('scene0054_00', 'train'), ('scene0055_00', 'train'), ('scene0056_00', 'train'), ('scene0057_00', 'train'), ('scene0058_00', 'train'), ('scene0059_00', 'train'), ('scene0060_00', 'train'), ('scene0061_00', 'train'), ('scene0062_00', 'train'), ('scene0063_00', 'train'), ('scene0064_00', 'train'), ('scene0065_00', 'train'), ('scene0066_00', 'train'), ('scene0067_00', 'train'), ('scene0068_00', 'train'), ('scene0069_00', 'train'), ('scene0070_00', 'train'), ('scene0071_00', 'train'), ('scene0072_00', 'train'), ('scene0073_00', 'train'), ('scene0074_00', 'train'), ('scene0075_00', 'train'), ('scene0076_00', 'train'), ('scene0077_00', 'train'), ('scene0078_00', 'train'), ('scene0079_00', 'train'), ('scene0080_00', 'train'), ('scene0081_00', 'train'), ('scene0082_00', 'train'), ('scene0083_00', 'train'), ('scene0084_00', 'train'), ('scene0085_00', 'train'), ('scene0086_00', 'train'), ('scene0087_00', 'train'), ('scene0088_00', 'train'), ('scene0089_00', 'train'), ('scene0090_00', 'train'), ('scene0091_00', 'train'), ('scene0092_00', 'train'), ('scene0093_00', 'train'), ('scene0094_00', 'train'), ('scene0095_00', 'train'), ('scene0096_00', 'train'), ('scene0097_00', 'train'), ('scene0098_00', 'train'), ('scene0099_00', 'train'), ('scene0100_00', 'train'), ('scene0101_00', 'train'), ('scene0102_00', 'train'), ('scene0103_00', 'train'), ('scene0104_00', 'train'), ('scene0105_00', 'train'), ('scene0106_00', 'train'), ('scene0107_00', 'train'), ('scene0108_00', 'train'), ('scene0109_00', 'train'), ('scene0110_00', 'train'), ('scene0111_00', 'train'), ('scene0112_00', 'train'), ('scene0113_00', 'train'), ('scene0114_00', 'train'), ('scene0115_00', 'train'), ('scene0116_00', 'train'), ('scene0117_00', 'train'), ('scene0118_00', 'train'), ('scene0119_00', 'train'), ('scene0120_00', 'train'), ('scene0121_00', 'train'), ('scene0122_00', 'train'), ('scene0123_00', 'train'), ('scene0124_00', 'train'), ('scene0125_00', 'train'), ('scene0126_00', 'train'), ('scene0127_00', 'train'), ('scene0128_00', 'train'), ('scene0129_00', 'train'), ('scene0130_00', 'train'), ('scene0131_00', 'train'), ('scene0132_00', 'train'), ('scene0133_00', 'train'), ('scene0134_00', 'train'), ('scene0135_00', 'train'), ('scene0136_00', 'train'), ('scene0137_00', 'train'), ('scene0138_00', 'train'), ('scene0139_00', 'train'), ('scene0140_00', 'train'), ('scene0141_00', 'train'), ('scene0142_00', 'train'), ('scene0143_00', 'train'), ('scene0144_00', 'train'), ('scene0145_00', 'train'), ('scene0146_00', 'train'), ('scene0147_00', 'train'), ('scene0148_00', 'train'), ('scene0149_00', 'train'), ('scene0150_00', 'train'), ('scene0151_00', 'train'), ('scene0152_00', 'train'), ('scene0153_00', 'train'), ('scene0154_00', 'train'), ('scene0155_00', 'train'), ('scene0156_00', 'train'), ('scene0157_00', 'train'), ('scene0158_00', 'train'), ('scene0159_00', 'train'), ('scene0161_00', 'train'), ('scene0162_00', 'train'), ('scene0163_00', 'train'), ('scene0164_00', 'train'), ('scene0165_00', 'train'), ('scene0166_00', 'train'), ('scene0167_00', 'train'), ('scene0168_00', 'train'), ('scene0169_00', 'train'), ('scene0170_00', 'train'), ('scene0171_00', 'train'), ('scene0172_00', 'train'), ('scene0173_00', 'train'), ('scene0174_00', 'train'), ('scene0175_00', 'train'), ('scene0176_00', 'train'), ('scene0177_00', 'train'), ('scene0178_00', 'train'), ('scene0179_00', 'train'), ('scene0180_00', 'train'), ('scene0181_00', 'train'), ('scene0182_00', 'train'), ('scene0183_00', 'train'), ('scene0184_00', 'train'), ('scene0185_00', 'train'), ('scene0186_00', 'train'), ('scene0187_00', 'train'), ('scene0188_00', 'train'), ('scene0189_00', 'train'), ('scene0190_00', 'train'), ('scene0191_00', 'train'), ('scene0192_00', 'train'), ('scene0193_00', 'train'), ('scene0194_00', 'train'), ('scene0195_00', 'train'), ('scene0196_00', 'train'), ('scene0197_00', 'train'), ('scene0198_00', 'train'), ('scene0199_00', 'train')]\n",
      "[('scene0200_00', 'val'), ('scene0211_00', 'val'), ('scene0226_00', 'val')]\n",
      "[('scene0160_00', 'test'), ('scene0204_00', 'test'), ('scene0211_00', 'test'), ('scene0217_00', 'test'), ('scene0218_00', 'test'), ('scene0225_00', 'test'), ('scene0227_00', 'test'), ('scene0340_01', 'test'), ('scene0376_02', 'test'), ('scene0643_00', 'test')]\n"
     ]
    }
   ],
   "source": [
    "for split in ['train','val','test']:\n",
    "    with Pool(processes=32) as pool:\n",
    "        # for scene_id in split2file_list[split]:\n",
    "        #     input_data = [scene_id,split]\n",
    "        files = split2file_list[split]\n",
    "        input_data = list(zip(files,[split]*len(files)))\n",
    "        print(input_data)\n",
    "        results = pool.starmap(prepare_dataset_by_id, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b8fec757-8af8-4a55-a9b3-2ce02ff389aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/data/chengshun.wang/scannet_2d/img_dir/train'\n",
    "for i in os.listdir(path):\n",
    "    img = np.asarray(Image.open(os.path.join(path,i)))\n",
    "    assert img.shape == (240,320,3),f\"img.shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2550c8cf-b558-4720-9c6f-176471ce01c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "121a563f-2153-4047-94ca-6d50d4a6f768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313591"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/mnt/data/chengshun.wang/scannet_2d/ann_dir/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "346f2c4c-679e-462a-9461-f0aa44529f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5089"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/mnt/data/chengshun.wang/scannet_2d/ann_dir/val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1ebf934-e20e-472e-b753-d151ffa06268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13224"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/mnt/data/chengshun.wang/scannet_2d/ann_dir/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a02e55ed-85bb-443e-b6a7-700f7a398082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mscene0160_00_0.jpg\u001b[0m  \u001b[01;35mscene0160_00_637.jpg\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls /mnt/data/chengshun.wang/scannet_2d/img_dir/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5a62cd9-2ac2-4497-bed7-153935fff40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train  val\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/data/chengshun.wang/scannet_2d/ann_dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beb590cc-5307-4575-a25b-07dfd66f54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(0,100,(10,10),dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfc3d92f-7777-4868-b6ac-12b4b12f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(data, mode='L').save('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11babdf7-0b38-4b0f-8b63-7f4aa7df959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load = Image.open('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "423d6247-780e-42b2-8e7c-ee029a9da93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load = np.asarray(data_load,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82cbc501-c4ef-4742-b0f4-3311231aa1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 36, 49, 37, 43, 98, 35, 35, 95, 18],\n",
       "       [49, 73, 13, 22, 12, 90, 44, 26, 26, 33],\n",
       "       [ 9, 18, 72, 66, 12, 87, 19, 64, 19, 10],\n",
       "       [72, 96, 22, 91, 85, 50, 51, 37, 16, 62],\n",
       "       [71, 42, 68, 13, 50, 88, 55, 30, 21, 89],\n",
       "       [ 3, 42, 88, 78, 75, 37, 85, 50, 35, 36],\n",
       "       [54,  4, 44,  2, 81, 12, 17, 88, 63, 74],\n",
       "       [63, 49, 72, 87, 68,  8, 26, 61, 21, 24],\n",
       "       [38, 38, 72,  1, 48, 15, 42, 75, 49, 69],\n",
       "       [61, 14, 54, 94, 41, 34, 52, 97, 40, 36]], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28b13866-083e-464b-8f5e-696537e87455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 36, 49, 37, 43, 98, 35, 35, 95, 18],\n",
       "       [49, 73, 13, 22, 12, 90, 44, 26, 26, 33],\n",
       "       [ 9, 18, 72, 66, 12, 87, 19, 64, 19, 10],\n",
       "       [72, 96, 22, 91, 85, 50, 51, 37, 16, 62],\n",
       "       [71, 42, 68, 13, 50, 88, 55, 30, 21, 89],\n",
       "       [ 3, 42, 88, 78, 75, 37, 85, 50, 35, 36],\n",
       "       [54,  4, 44,  2, 81, 12, 17, 88, 63, 74],\n",
       "       [63, 49, 72, 87, 68,  8, 26, 61, 21, 24],\n",
       "       [38, 38, 72,  1, 48, 15, 42, 75, 49, 69],\n",
       "       [61, 14, 54, 94, 41, 34, 52, 97, 40, 36]], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7db5ec1e-3507-4d0a-b4e0-fdd5d7ccc0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(Image.open('data/scannet/scene0000_00/label-filt/100.png'), dtype=np.int32).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b17b823c-040a-4f9a-9071-c484207cb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 创建形状为(100, 100, 1)的示例语义分割图\n",
    "semantic_segmentation_tensor = np.random.randint(0, 256, size=(100, 100, 1), dtype=np.uint8)\n",
    "\n",
    "# 将numpy数组转换为PIL图像\n",
    "semantic_segmentation_image = Image.fromarray(semantic_segmentation_tensor.squeeze(), mode='L')\n",
    "\n",
    "# 保存PIL图像为PNG文件\n",
    "semantic_segmentation_image.save('semantic_segmentation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a167bf7-a876-4553-a90a-4ce6ac9b46a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_image = Image.open('semantic_segmentation.png')\n",
    "\n",
    "# 将加载的图像转换为NumPy数组\n",
    "loaded_semantic_segmentation_tensor = np.array(loaded_image)\n",
    "\n",
    "# 如果需要将通道数恢复为 1（从灰度图像中加载）\n",
    "if len(loaded_semantic_segmentation_tensor.shape) == 2:\n",
    "    loaded_semantic_segmentation_tensor = loaded_semantic_segmentation_tensor[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eeec6e43-bf88-43a2-8a83-0bdd9c48632a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 227,  13, ..., 182, 205,  33], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_segmentation_tensor.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17235f7b-623e-4d0a-b882-0ce6aa56337a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 227,  13, ..., 182, 205,  33], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_semantic_segmentation_tensor.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d30b18d4-5e52-4c64-b347-83c5428b56d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'111zzz.png'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(111)+os.path.basename('xxx/yyy/zzz.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2f7e2d3-27a3-4c54-97b9-f8071fe88bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 36, 49, 37, 43, 98, 35, 35, 95, 18],\n",
       "       [49, 73, 13, 22, 12, 90, 44, 26, 26, 33],\n",
       "       [ 9, 18, 72, 66, 12, 87, 19, 64, 19, 10],\n",
       "       [72, 96, 22, 91, 85, 50, 51, 37, 16, 62],\n",
       "       [71, 42, 68, 13, 50, 88, 55, 30, 21, 89],\n",
       "       [ 3, 42, 88, 78, 75, 37, 85, 50, 35, 36],\n",
       "       [54,  4, 44,  2, 81, 12, 17, 88, 63, 74],\n",
       "       [63, 49, 72, 87, 68,  8, 26, 61, 21, 24],\n",
       "       [38, 38, 72,  1, 48, 15, 42, 75, 49, 69],\n",
       "       [61, 14, 54, 94, 41, 34, 52, 97, 40, 36]], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2f525ce-753c-435b-9973-fe1d2b727fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 12, 22]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1,22,12,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c412dc8-83f0-48f6-8d30-13c3b76de78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imread('/home/chengshun.wang/pjs/Semantic-Ray/data/scannet/scene0000_00/color/0.jpg').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b22f0-f05e-47ef-bf82-c55634016bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010871a-074a-472a-9bcc-3a6b5e8e2302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af205a-c82f-4661-8523-a7cce801dfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
